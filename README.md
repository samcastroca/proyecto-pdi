# ğŸ” DetecciÃ³n de ImÃ¡genes: Real vs. AI

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/samcastroca/proyecto-pdi/blob/main/notebooks/train.ipynb)
[![Hugging Face Spaces](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Demo-blue)](https://huggingface.co/juandaram/deepfake-detector)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**ClasificaciÃ³n Binaria con Transfer Learning (ResNet50)**

> Proyecto de Deep Learning para detectar imÃ¡genes generadas por IA vs. imÃ¡genes reales.

**Autores:** Samuel Castro, Juan David RamÃ­rez Ortiz

---

## ğŸ“‹ Tabla de Contenidos

- [El Problema](#-el-problema)
- [SoluciÃ³n Propuesta](#-soluciÃ³n-propuesta)
- [Dataset](#-dataset)
- [Arquitectura del Modelo](#-arquitectura-del-modelo)
- [Resultados](#-resultados)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
  - [Inferencia Local](#inferencia-local)
  - [API de Hugging Face](#api-de-hugging-face)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Limitaciones](#-limitaciones)
- [Conclusiones](#-conclusiones)
- [Licencia](#-licencia)

---

## ğŸ¯ El Problema

### El DesafÃ­o: Deepfakes y GeneraciÃ³n AI

La proliferaciÃ³n de modelos generativos permite crear imÃ¡genes sintÃ©ticas indistinguibles a simple vista. Es necesario automatizar la distinciÃ³n entre contenido autÃ©ntico y generado.

**Impacto:**
- ğŸ“° PrevenciÃ³n de desinformaciÃ³n (Fake News)
- ğŸ” ValidaciÃ³n de identidad y seguridad digital
- ğŸŒ Filtrado de contenido en redes sociales

---

## ğŸ’¡ SoluciÃ³n Propuesta

| Aspecto | DescripciÃ³n |
|---------|-------------|
| **Tarea** | ClasificaciÃ³n Binaria de ImÃ¡genes |
| **Clases** | `REAL` (1) vs. `FAKE` (0) |
| **Modelo** | Red Neuronal Convolucional (CNN) |
| **TÃ©cnica** | Transfer Learning (Fine-tuning parcial) |
| **Base** | ResNet50 pre-entrenada en ImageNet |

---

## ğŸ“Š Dataset

El modelo fue entrenado utilizando el dataset **CIFAKE**, que contiene imÃ¡genes reales e imÃ¡genes generadas por IA.

### Estructura del Dato

| CaracterÃ­stica | Valor |
|----------------|-------|
| **ResoluciÃ³n Original** | 32 Ã— 32 pÃ­xeles (RGB) |
| **ResoluciÃ³n de Entrada** | 128 Ã— 128 pÃ­xeles (upscaling) |
| **NormalizaciÃ³n** | Rescale 1./255 |

### DistribuciÃ³n

| Set | Cantidad | DistribuciÃ³n |
|-----|----------|--------------|
| Entrenamiento (Train) | 100,000 imÃ¡genes | Balanceado (50/50) |
| Prueba (Test) | 20,000 imÃ¡genes | Balanceado (50/50) |
| **Total** | **120,000 imÃ¡genes** | |

---

## ğŸ—ï¸ Arquitectura del Modelo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input     â”‚â”€â”€â”€â–¶â”‚    ResNet50      â”‚â”€â”€â”€â–¶â”‚   Ãšltimas 10    â”‚â”€â”€â”€â–¶â”‚ Global Avg  â”‚â”€â”€â”€â–¶â”‚  Dense 256  â”‚â”€â”€â”€â–¶â”‚ Sigmoid â”‚
â”‚ 128Ã—128Ã—3   â”‚    â”‚   (Congelado)    â”‚    â”‚    Capas        â”‚    â”‚  Pooling    â”‚    â”‚ + Dropout   â”‚    â”‚  Output â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   (ImageNet)     â”‚    â”‚  (Trainable)    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   (0.5)     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraciÃ³n del Modelo

- **Base:** ResNet50 (Weights: ImageNet)
- **Congelamiento:** Todas las capas excepto las Ãºltimas 10
- **Cabezal (Head):**
  - GlobalAveragePooling2D
  - Dense (256 neuronas, ReLU) + Dropout (0.5)
  - Salida: Dense (1 neurona, Sigmoid)
- **Optimizador:** Adam (lr=1e-5)
- **Loss:** Binary Crossentropy

### Componentes

| Componente | DescripciÃ³n |
|------------|-------------|
| Extractor de caracterÃ­sticas | Capas congeladas de ResNet50 |
| Fine-tuning | Ãšltimas 10 capas entrenables |
| Clasificador | Capas densas personalizadas |

---

## ğŸ“ˆ Resultados

### MÃ©tricas Finales (Ã‰poca 5)

| MÃ©trica | Valor |
|---------|-------|
| **Train Accuracy** | 87.25% |
| **Val Accuracy** | 84.90% (Pico: 86.76%) |
| **Train Loss** | 0.3026 |

### OptimizaciÃ³n del Modelo

Comparativa de formatos para despliegue:

| Formato | Peso Aprox. | Velocidad | Caso de Uso |
|---------|-------------|-----------|-------------|
| Keras (.h5/.keras) | ~95 MB | Lento | Entrenamiento |
| TorchScript / ONNX | ~90 MB | Medio | Servidor Cloud |
| **LiteRT (TFLite)** | **~25 MB** | **RÃ¡pido** | **MÃ³vil / Edge** |

---

## âš™ï¸ InstalaciÃ³n

### Requisitos Previos

- Python 3.7+
- pip

### Clonar el Repositorio

```bash
git clone https://github.com/samcastroca/proyecto-pdi.git
cd proyecto-pdi
```

### Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Dependencias Principales

```bash
pip install tensorflow numpy matplotlib pillow requests
```

---

## ğŸš€ Uso

### Inferencia Local

El script de inferencia local utiliza el modelo TFLite optimizado para mÃ¡xima velocidad.

#### Flujo de EjecuciÃ³n

1. **Carga:** Recibe la ruta de la imagen y del modelo `.tflite` por lÃ­nea de comandos
2. **Preprocesamiento:**
   - Redimensiona a 128 Ã— 128 pÃ­xeles
   - Normaliza pÃ­xeles al rango [0, 1]
   - AÃ±ade dimensiÃ³n Batch (1, 128, 128, 3)
3. **Inferencia:** Usa `tf.lite.Interpreter` (sin cargar Keras completo)
4. **Post-procesamiento:** Decodifica la salida Sigmoid y genera visualizaciÃ³n

#### Comando BÃ¡sico

```bash
python src/local_predict/inference_script.py <ruta_imagen>
```

#### Ejemplos

```bash
# Usar modelo por defecto
python src/local_predict/inference_script.py imgs/fake/5.jpg

# Especificar modelo personalizado
python src/local_predict/inference_script.py mi_imagen.jpg --model_path models/model.tflite
```

#### Argumentos

| Argumento | DescripciÃ³n | Default |
|-----------|-------------|---------|
| `image_path` | Ruta a la imagen de entrada (requerido) | - |
| `--model_path` | Ruta al modelo TFLite | `models/model_litert.tflite` |

#### Salida

El script genera:
- VisualizaciÃ³n con la imagen original y redimensionada
- PredicciÃ³n final: `REAL` o `FAKE`
- Nivel de confianza (0-1)
- Archivo de imagen con resultados: `<nombre_imagen>_results.png`

#### LÃ³gica de ClasificaciÃ³n

```python
# Preprocesamiento (idÃ©ntico al entrenamiento)
image = image.resize((128, 128))
input_data = np.array(image) / 255.0

# Inferencia TFLite
interpreter.allocate_tensors()
interpreter.set_tensor(idx, input_data)
interpreter.invoke()
output = interpreter.get_tensor(idx)

# ClasificaciÃ³n binaria (Umbral: 0.5)
if output[0][0] > 0.5:
    label = "REAL"   # Confianza = output
else:
    label = "FAKE"   # Confianza = 1 - output
```

---

### API de Hugging Face

El modelo estÃ¡ desplegado en Hugging Face Spaces con una interfaz Gradio para pruebas rÃ¡pidas.

#### Demo Web

ğŸŒ **URL:** [https://juandaram-deepfake-detector-api.hf.space](https://juandaram-deepfake-detector-api.hf.space)

Simplemente:
1. Sube una imagen
2. ObtÃ©n la probabilidad Real/Fake

#### Usar desde Python

```bash
python src/hugging_face/predict_gradio_api.py <ruta_imagen>
```

---

## ğŸ“ Estructura del Proyecto

```
proyecto-pdi/
â”œâ”€â”€ docs/                          # DocumentaciÃ³n
â”œâ”€â”€ imgs/                          # ImÃ¡genes de ejemplo
â”‚   â”œâ”€â”€ fake/                      # ImÃ¡genes fake para testing
â”‚   â””â”€â”€ real/                      # ImÃ¡genes reales para testing
â”œâ”€â”€ models/                        # Modelos entrenados
â”‚   â”œâ”€â”€ model.tflite              # Modelo TFLite optimizado
â”‚   â””â”€â”€ saved_model/              # Modelo SavedModel de TensorFlow
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ train.ipynb               # Notebook de entrenamiento
â”‚   â””â”€â”€ convert_litert.ipynb      # ConversiÃ³n a TFLite
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ local_predict/
â”‚   â”‚   â”œâ”€â”€ inference_script.py   # Script de inferencia local
â”‚   â”‚   â””â”€â”€ debug_inference.py    # Script de debugging
â”‚   â”œâ”€â”€ hugging_face/
â”‚   â”‚   â”œâ”€â”€ predict_gradio_api.py # Cliente API de Gradio
â”‚   â”‚   â”œâ”€â”€ predict_hf_api.py     # Cliente API de HF
â”‚   â”‚   â””â”€â”€ upload_hf.py          # Script para subir a HF
â”‚   â”œâ”€â”€ data/                     # Scripts de procesamiento de datos
â”‚   â”œâ”€â”€ features/                 # Feature engineering
â”‚   â”œâ”€â”€ models/                   # Definiciones de modelos
â”‚   â””â”€â”€ visualization/            # Scripts de visualizaciÃ³n
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                  # GrÃ¡ficas y figuras generadas
â”œâ”€â”€ references/                   # Recursos y referencias
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ setup.py                      # ConfiguraciÃ³n del paquete
â”œâ”€â”€ Makefile                      # Comandos de automatizaciÃ³n
â””â”€â”€ README.md                     # Este archivo
```

---

## âš ï¸ Limitaciones

| LimitaciÃ³n | DescripciÃ³n |
|------------|-------------|
| **ResoluciÃ³n** | El upscale de 32 a 128px puede introducir artefactos no deseados |
| **Ã‰pocas** | Se entrenÃ³ solo por 5 Ã©pocas; podrÃ­a mejorar con mÃ¡s tiempo |
| **GeneralizaciÃ³n** | Necesario probar con imÃ¡genes de alta calidad (no CIFAR/thumbnails) |

---

## ğŸ“ Conclusiones

- **Eficacia de ResNet50:** A pesar de usar imÃ¡genes pequeÃ±as escaladas, el modelo pre-entrenado logra casi un 87% de precisiÃ³n rÃ¡pidamente.

- **Fine-Tuning:** Descongelar las Ãºltimas 10 capas fue crucial para adaptar las caracterÃ­sticas de ImageNet al dominio sintÃ©tico.

- **Escalabilidad:** Con 120,000 imÃ¡genes, el dataset es robusto, pero el modelo se beneficiarÃ­a de Data Augmentation mÃ¡s agresivo para reducir el overfitting leve.

---

## ğŸ”§ Desarrollo

### Entrenar el Modelo

Abre el notebook en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/samcastroca/proyecto-pdi/blob/main/notebooks/train.ipynb)

### Convertir a TFLite

```bash
# Usar el notebook de conversiÃ³n
jupyter notebook notebooks/convert_litert.ipynb
```

### Tests

```bash
python src/test_model.py
python src/test_savedmodel.py
```

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

- **Samuel Castro** - [@samcastroca](https://github.com/samcastroca)
- **Juan David RamÃ­rez Ortiz**

---

<p align="center">
  <i>Proyecto de Deep Learning - 2025</i>
</p>
